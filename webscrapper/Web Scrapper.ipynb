{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia header tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe arts\\nBiography\\nGeography\\nHistory\\nMathematics\\nScience\\nSociety\\nTechnology\\nAll portals\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page?')\n",
    "soup=BeautifulSoup(page.content)\n",
    "tag=soup.find_all('ul',id=\"mp-portals\")\n",
    "header_tag=[]\n",
    "for i in tag:\n",
    "    header_tag.append(i.text)\n",
    "header_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imdb top 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption(1994)',\n",
       " '2.The Godfather(1972)',\n",
       " '3.The Godfather: Part II(1974)',\n",
       " '4.The Dark Knight(2008)',\n",
       " '5.12 Angry Men(1957)',\n",
       " \"6.Schindler's List(1993)\",\n",
       " '7.The Lord of the Rings: The Return of the King(2003)',\n",
       " '8.Pulp Fiction(1994)',\n",
       " '9.Il buono, il brutto, il cattivo(1966)',\n",
       " '10.Fight Club(1999)',\n",
       " '11.Joker(2019)',\n",
       " '12.The Lord of the Rings: The Fellowship of the Ring(2001)',\n",
       " '13.Forrest Gump(1994)',\n",
       " '14.Inception(2010)',\n",
       " '15.Star Wars: Episode V - The Empire Strikes Back(1980)',\n",
       " '16.The Lord of the Rings: The Two Towers(2002)',\n",
       " '17.The Matrix(1999)',\n",
       " \"18.One Flew Over the Cuckoo's Nest(1975)\",\n",
       " '19.Goodfellas(1990)',\n",
       " '20.Shichinin no samurai(1954)',\n",
       " '21.Se7en(1995)',\n",
       " '22.Cidade de Deus(2002)',\n",
       " '23.La vita è bella(1997)',\n",
       " '24.The Silence of the Lambs(1991)',\n",
       " '25.Star Wars(1977)',\n",
       " \"26.It's a Wonderful Life(1946)\",\n",
       " '27.Saving Private Ryan(1998)',\n",
       " '28.Sen to Chihiro no kamikakushi(2001)',\n",
       " '29.The Green Mile(1999)',\n",
       " '30.Léon(1994)',\n",
       " '31.Seppuku(1962)',\n",
       " '32.Interstellar(2014)',\n",
       " '33.The Usual Suspects(1995)',\n",
       " '34.The Lion King(1994)',\n",
       " '35.American History X(1998)',\n",
       " '36.Back to the Future(1985)',\n",
       " '37.The Pianist(2002)',\n",
       " '38.Modern Times(1936)',\n",
       " '39.Terminator 2: Judgment Day(1991)',\n",
       " '40.The Intouchables(2011)',\n",
       " '41.Psycho(1960)',\n",
       " '42.Gladiator(2000)',\n",
       " '43.City Lights(1931)',\n",
       " '44.The Departed(2006)',\n",
       " '45.Whiplash(2014)',\n",
       " '46.Once Upon a Time in the West(1968)',\n",
       " '47.The Prestige(2006)',\n",
       " '48.Avengers: Endgame(2019)',\n",
       " '49.Casablanca(1942)',\n",
       " '50.Hotaru no haka(1988)',\n",
       " '51.Rear Window(1954)',\n",
       " '52.Nuovo Cinema Paradiso(1988)',\n",
       " '53.Alien(1979)',\n",
       " '54.Raiders of the Lost Ark(1981)',\n",
       " '55.Memento(2000)',\n",
       " '56.Apocalypse Now(1979)',\n",
       " '57.The Great Dictator(1940)',\n",
       " '58.The Lives of Others(2006)',\n",
       " '59.Avengers: Infinity War(2018)',\n",
       " '60.Django Unchained(2012)',\n",
       " '61.Spider-Man: Into the Spider-Verse(2018)',\n",
       " '62.The Shining(1980)',\n",
       " '63.Paths of Glory(1957)',\n",
       " '64.WALL·E(2008)',\n",
       " '65.Sunset Blvd.(1950)',\n",
       " '66.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)',\n",
       " '67.Mononoke-hime(1997)',\n",
       " '68.Oldeuboi(2003)',\n",
       " '69.Witness for the Prosecution(1957)',\n",
       " '70.The Dark Knight Rises(2012)',\n",
       " '71.Once Upon a Time in America(1984)',\n",
       " '72.Gisaengchung(2019)',\n",
       " '73.Aliens(1986)',\n",
       " '74.American Beauty(1999)',\n",
       " '75.Coco(I) (2017)',\n",
       " '76.Kimi no na wa.(2016)',\n",
       " '77.Braveheart(1995)',\n",
       " '78.Das Boot(1981)',\n",
       " '79.3 Idiots(2009)',\n",
       " '80.Taare Zameen Par(2007)',\n",
       " '81.Star Wars: Episode VI - Return of the Jedi(1983)',\n",
       " '82.Toy Story(1995)',\n",
       " '83.Reservoir Dogs(1992)',\n",
       " '84.Amadeus(1984)',\n",
       " '85.Dangal(2016)',\n",
       " '86.Good Will Hunting(1997)',\n",
       " '87.Inglourious Basterds(2009)',\n",
       " '88.M - Eine Stadt sucht einen Mörder(1931)',\n",
       " '89.Requiem for a Dream(2000)',\n",
       " '90.2001: A Space Odyssey(1968)',\n",
       " '91.Vertigo(1958)',\n",
       " '92.Eternal Sunshine of the Spotless Mind(2004)',\n",
       " '93.Citizen Kane(1941)',\n",
       " '94.Full Metal Jacket(1987)',\n",
       " '95.Jagten(2012)',\n",
       " '96.North by Northwest(1959)',\n",
       " '97.A Clockwork Orange(1971)',\n",
       " '98.Snatch(2000)',\n",
       " '99.Amélie(2001)',\n",
       " '100.The Kid(1921)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all(\"h3\",class_=\"lister-item-header\")\n",
    "movie_name=[]\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_all=soup.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "rating=[]\n",
    "for i in rating_all:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(1974)',\n",
       " '(2008)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(1990)',\n",
       " '(1954)',\n",
       " '(1995)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1946)',\n",
       " '(1998)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(1994)',\n",
       " '(1962)',\n",
       " '(2014)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1998)',\n",
       " '(1985)',\n",
       " '(2002)',\n",
       " '(1936)',\n",
       " '(1991)',\n",
       " '(2011)',\n",
       " '(1960)',\n",
       " '(2000)',\n",
       " '(1931)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(1968)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1940)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(1980)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(1950)',\n",
       " '(1964)',\n",
       " '(1997)',\n",
       " '(2003)',\n",
       " '(1957)',\n",
       " '(2012)',\n",
       " '(1984)',\n",
       " '(2019)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " '(I) (2017)',\n",
       " '(2016)',\n",
       " '(1995)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(1983)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2009)',\n",
       " '(1931)',\n",
       " '(2000)',\n",
       " '(1968)',\n",
       " '(1958)',\n",
       " '(2004)',\n",
       " '(1941)',\n",
       " '(1987)',\n",
       " '(2012)',\n",
       " '(1959)',\n",
       " '(1971)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(1921)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_all=soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year=[]\n",
    "for i in year_all:\n",
    "    year.append(i.text.replace(\"\\n\",\"\"))\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption(1994)</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather(1972)</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Godfather: Part II(1974)</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Dark Knight(2008)</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.12 Angry Men(1957)</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.North by Northwest(1959)</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.A Clockwork Orange(1971)</td>\n",
       "      <td>(1971)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Snatch(2000)</td>\n",
       "      <td>(2000)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Amélie(2001)</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.The Kid(1921)</td>\n",
       "      <td>(1921)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name    Year Rating\n",
       "0   1.The Shawshank Redemption(1994)  (1994)    9.3\n",
       "1              2.The Godfather(1972)  (1972)    9.2\n",
       "2     3.The Godfather: Part II(1974)  (1974)      9\n",
       "3            4.The Dark Knight(2008)  (2008)      9\n",
       "4               5.12 Angry Men(1957)  (1957)      9\n",
       "..                               ...     ...    ...\n",
       "95       96.North by Northwest(1959)  (1959)    8.3\n",
       "96       97.A Clockwork Orange(1971)  (1971)    8.3\n",
       "97                   98.Snatch(2000)  (2000)    8.3\n",
       "98                   99.Amélie(2001)  (2001)    8.3\n",
       "99                 100.The Kid(1921)  (1921)    8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Name']=movie_name\n",
    "df['Year']=year\n",
    "df['Rating']=rating\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imdb top 100 Bollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.Rang De Basanti(2006)',\n",
       " '2.3 Idiots(2009)',\n",
       " '3.Taare Zameen Par(2007)',\n",
       " '4.Dil Chahta Hai(2001)',\n",
       " '5.Swades: We, the People(2004)',\n",
       " '6.Lagaan: Once Upon a Time in India(2001)',\n",
       " '7.Gangs of Wasseypur(2012)',\n",
       " '8.Barfi!(2012)',\n",
       " '9.Anand(1971)',\n",
       " '10.Munna Bhai M.B.B.S.(2003)',\n",
       " '11.A Wednesday(2008)',\n",
       " '12.Andaz Apna Apna(1994)',\n",
       " '13.Sholay(1975)',\n",
       " '14.Bhaag Milkha Bhaag(2013)',\n",
       " '15.Hera Pheri(2000)',\n",
       " '16.Udaan(2010)',\n",
       " '17.Kahaani(2012)',\n",
       " '18.Black(2005)',\n",
       " '19.Chak De! India(2007)',\n",
       " '20.Khosla Ka Ghosla!(2006)',\n",
       " '21.Jo Jeeta Wohi Sikandar(1992)',\n",
       " '22.Zindagi Na Milegi Dobara(2011)',\n",
       " '23.Paan Singh Tomar(2012)',\n",
       " '24.Dilwale Dulhania Le Jayenge(1995)',\n",
       " '25.Omkara(2006)',\n",
       " '26.Lage Raho Munna Bhai(2006)',\n",
       " '27.Iqbal(2005)',\n",
       " '28.The Lunchbox(2013)',\n",
       " '29.Black Friday(2004)',\n",
       " '30.Company(2002)',\n",
       " '31.Golmaal(1979)',\n",
       " '32.Dev.D(2009)',\n",
       " '33.Jaane Bhi Do Yaaro(1983)',\n",
       " '34.OMG: Oh My God!(2012)',\n",
       " '35.Mughal-E-Azam(1960)',\n",
       " '36.Gulaal(2009)',\n",
       " '37.Dor(2006)',\n",
       " '38.Jab We Met(2007)',\n",
       " '39.Pyaasa(1957)',\n",
       " '40.The Legend of Bhagat Singh(2002)',\n",
       " '41.Masoom(1983)',\n",
       " '42.Salaam Bombay!(1988)',\n",
       " '43.Satya(1998)',\n",
       " '44.Vicky Donor(2012)',\n",
       " '45.Lakshya(2004)',\n",
       " '46.Vaastav: The Reality(1999)',\n",
       " '47.Kal Ho Naa Ho(2003)',\n",
       " '48.Oye Lucky! Lucky Oye!(2008)',\n",
       " '49.Sarfarosh(1999)',\n",
       " '50.Gangaajal(2003)',\n",
       " '51.Angoor(1982)',\n",
       " '52.Madras Cafe(2013)',\n",
       " '53.English Vinglish(2012)',\n",
       " '54.Chupke Chupke(1975)',\n",
       " '55.Johnny Gaddaar(2007)',\n",
       " '56.Maqbool(2003)',\n",
       " '57.Hazaaron Khwaishein Aisi(2003)',\n",
       " '58.Rock On!!(2008)',\n",
       " '59.Don(1978)',\n",
       " '60.Chhoti Si Baat(1976)',\n",
       " '61.Guide(1965)',\n",
       " '62.Raanjhanaa(2013)',\n",
       " '63.Deewaar(1975)',\n",
       " '64.Special Chabbis(2013)',\n",
       " '65.Padosan(1968)',\n",
       " '66.Mumbai Meri Jaan(2008)',\n",
       " '67.Ab Tak Chhappan(2004)',\n",
       " '68.Kai po che!(2013)',\n",
       " '69.Awaara(1951)',\n",
       " '70.Shree 420(1955)',\n",
       " '71.Earth(1998)',\n",
       " '72.Gunda(1998)',\n",
       " '73.Parinda(1989)',\n",
       " '74.Dasvidaniya(2008)',\n",
       " '75.Hey Ram(2000)',\n",
       " '76.Pinjar: Beyond Boundaries...(2003)',\n",
       " '77.Socha Na Tha(2005)',\n",
       " '78.Guru(2007)',\n",
       " '79.Bawarchi(1972)',\n",
       " '80.Manorama: Six Feet Under(2007)',\n",
       " '81.Mr. India(1987)',\n",
       " '82.Aamir(2008)',\n",
       " '83.Zakhm(1998)',\n",
       " '84.Water(I) (2005)',\n",
       " '85.Stanley Ka Dabba(2011)',\n",
       " '86.Agneepath(1990)',\n",
       " '87.My Name Is Khan(2010)',\n",
       " '88.Qayamat Se Qayamat Tak(1988)',\n",
       " '89.3 Deewarein(2003)',\n",
       " '90.Abhimaan(1973)',\n",
       " '91.Sarkar(2005)',\n",
       " '92.Bheja Fry(2007)',\n",
       " '93.Mother India(1957)',\n",
       " '94.Jaane Tu... Ya Jaane Na(2008)',\n",
       " '95.Delhi Belly(2011)',\n",
       " '96.Wake Up Sid(2009)',\n",
       " '97.Rangeela(1995)',\n",
       " '98.Shatranj Ke Khilari(1977)',\n",
       " '99.Pyaar Ka Punchnama(2011)',\n",
       " '100.Ek Hasina Thi(2004)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls009997493/')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all(\"h3\",class_=\"lister-item-header\")\n",
    "movie_name=[]\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.1',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '8',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '8',\n",
       " '7.9',\n",
       " '7.7',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '8',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '7.9',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '8',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '7.9',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '7.9',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '8',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '7.6',\n",
       " '7.5']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_all=soup.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "rating=[]\n",
    "for i in rating_all:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2006)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(2001)',\n",
       " '(2004)',\n",
       " '(2001)',\n",
       " '(2012)',\n",
       " '(2012)',\n",
       " '(1971)',\n",
       " '(2003)',\n",
       " '(2008)',\n",
       " '(1994)',\n",
       " '(1975)',\n",
       " '(2013)',\n",
       " '(2000)',\n",
       " '(2010)',\n",
       " '(2012)',\n",
       " '(2005)',\n",
       " '(2007)',\n",
       " '(2006)',\n",
       " '(1992)',\n",
       " '(2011)',\n",
       " '(2012)',\n",
       " '(1995)',\n",
       " '(2006)',\n",
       " '(2006)',\n",
       " '(2005)',\n",
       " '(2013)',\n",
       " '(2004)',\n",
       " '(2002)',\n",
       " '(1979)',\n",
       " '(2009)',\n",
       " '(1983)',\n",
       " '(2012)',\n",
       " '(1960)',\n",
       " '(2009)',\n",
       " '(2006)',\n",
       " '(2007)',\n",
       " '(1957)',\n",
       " '(2002)',\n",
       " '(1983)',\n",
       " '(1988)',\n",
       " '(1998)',\n",
       " '(2012)',\n",
       " '(2004)',\n",
       " '(1999)',\n",
       " '(2003)',\n",
       " '(2008)',\n",
       " '(1999)',\n",
       " '(2003)',\n",
       " '(1982)',\n",
       " '(2013)',\n",
       " '(2012)',\n",
       " '(1975)',\n",
       " '(2007)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2008)',\n",
       " '(1978)',\n",
       " '(1976)',\n",
       " '(1965)',\n",
       " '(2013)',\n",
       " '(1975)',\n",
       " '(2013)',\n",
       " '(1968)',\n",
       " '(2008)',\n",
       " '(2004)',\n",
       " '(2013)',\n",
       " '(1951)',\n",
       " '(1955)',\n",
       " '(1998)',\n",
       " '(1998)',\n",
       " '(1989)',\n",
       " '(2008)',\n",
       " '(2000)',\n",
       " '(2003)',\n",
       " '(2005)',\n",
       " '(2007)',\n",
       " '(1972)',\n",
       " '(2007)',\n",
       " '(1987)',\n",
       " '(2008)',\n",
       " '(1998)',\n",
       " '(I) (2005)',\n",
       " '(2011)',\n",
       " '(1990)',\n",
       " '(2010)',\n",
       " '(1988)',\n",
       " '(2003)',\n",
       " '(1973)',\n",
       " '(2005)',\n",
       " '(2007)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(2011)',\n",
       " '(2009)',\n",
       " '(1995)',\n",
       " '(1977)',\n",
       " '(2011)',\n",
       " '(2004)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_all=soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year=[]\n",
    "for i in year_all:\n",
    "    year.append(i.text.replace(\"\\n\",\"\"))\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Rang De Basanti(2006)</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3 Idiots(2009)</td>\n",
       "      <td>(2009)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.Taare Zameen Par(2007)</td>\n",
       "      <td>(2007)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.Dil Chahta Hai(2001)</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Swades: We, the People(2004)</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.Wake Up Sid(2009)</td>\n",
       "      <td>(2009)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Rangeela(1995)</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Shatranj Ke Khilari(1977)</td>\n",
       "      <td>(1977)</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Pyaar Ka Punchnama(2011)</td>\n",
       "      <td>(2011)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.Ek Hasina Thi(2004)</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Rating\n",
       "0          1.Rang De Basanti(2006)  (2006)    8.1\n",
       "1                 2.3 Idiots(2009)  (2009)    8.4\n",
       "2         3.Taare Zameen Par(2007)  (2007)    8.4\n",
       "3           4.Dil Chahta Hai(2001)  (2001)    8.1\n",
       "4   5.Swades: We, the People(2004)  (2004)    8.2\n",
       "..                             ...     ...    ...\n",
       "95            96.Wake Up Sid(2009)  (2009)    7.6\n",
       "96               97.Rangeela(1995)  (1995)    7.5\n",
       "97    98.Shatranj Ke Khilari(1977)  (1977)    7.7\n",
       "98     99.Pyaar Ka Punchnama(2011)  (2011)    7.6\n",
       "99         100.Ek Hasina Thi(2004)  (2004)    7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Name']=movie_name\n",
    "df['Year']=year\n",
    "df['Rating']=rating\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name genre and book review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ★ The Other Black Girl',\n",
       " ' ★ Walking on Cowrie Shells',\n",
       " 'Malibu Rising',\n",
       " 'Both Can Be True',\n",
       " ' ★ The One Hundred Years of Lenni and Margot',\n",
       " 'We Can’t Keep Meeting Like This',\n",
       " ' ★ The Ride of Her Life',\n",
       " ' ★ Golden Girl',\n",
       " 'The Road Trip',\n",
       " 'The Rescuer of Tiny Creatures']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://bookpage.com/reviews')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all(\"h4\",class_=\"italic\")\n",
    "book_name=[]\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        book_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "book_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zakiya Dalila Harris',\n",
       " 'Nana Nkweti',\n",
       " 'Taylor Jenkins Reid',\n",
       " 'Jules Machias',\n",
       " 'Marianne Cronin',\n",
       " 'Rachel Lynn Solomon',\n",
       " 'Elizabeth Letts',\n",
       " 'Elin Hilderbrand',\n",
       " \"Beth O'Leary\",\n",
       " 'Curtis Manley, Lucy Ruth Cummins']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name=soup.find_all(\"p\",class_=\"sans bold\")\n",
    "author=[]\n",
    "for i in author_name:\n",
    "    author.append(i.text.replace(\"\\n\",\"\"))\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fiction / Literary Fiction',\n",
       " 'Fiction / Short Stories',\n",
       " 'Fiction / Popular Fiction',\n",
       " \"Children's / Middle Grade\",\n",
       " 'Fiction / Popular Fiction',\n",
       " 'YA / YA Fiction',\n",
       " 'Nonfiction / Biography / Animals',\n",
       " 'Fiction / Family Drama',\n",
       " 'Romance / Contemporary Romance',\n",
       " \"Children's / Children's Picture Book\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_genre=soup.find_all(\"p\",class_=\"genre-links hidden-phone\")\n",
    "genre=[]\n",
    "for i in book_genre:\n",
    "    genre.append(i.text.replace(\"\\n\",\"\"))\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brilliantly positioned at the intersection of satire and social horror, Zakiya Dalila Harris’ debut novel is a genre-bending creative triumph.',\n",
       " 'With the ease of a master, Nana Nkweti shifts between points of view, between American and African slang, and between the straightforward and the avant-garde.',\n",
       " 'Malibu Rising is packed with plenty of scintillating scandal, but Taylor Jenkins Reid’s irresistible characters are the novel’s greatest success.',\n",
       " '',\n",
       " 'Even in the face of death’s inevitability, friendship can be found, forgiveness can flourish and fun can ease fear.',\n",
       " '',\n",
       " 'This is a feel-good story in every way, and Elizabeth Letts keeps the momentum lively, sprinkling in interesting historical tidbits that enrich the drama.',\n",
       " 'Killing off the main character just a few pages into a book is somewhat unorthodox, but it’s just the first of many interesting choices Elin Hilderbrand makes.',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_review=soup.find_all(\"p\",class_=\"excerpt\")\n",
    "review=[]\n",
    "for i in book_review:\n",
    "    review.append(i.text.replace(\"\\n\",\"\"))\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ The Other Black Girl</td>\n",
       "      <td>Zakiya Dalila Harris</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>Brilliantly positioned at the intersection of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>★ Walking on Cowrie Shells</td>\n",
       "      <td>Nana Nkweti</td>\n",
       "      <td>Fiction / Short Stories</td>\n",
       "      <td>With the ease of a master, Nana Nkweti shifts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malibu Rising</td>\n",
       "      <td>Taylor Jenkins Reid</td>\n",
       "      <td>Fiction / Popular Fiction</td>\n",
       "      <td>Malibu Rising is packed with plenty of scintil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both Can Be True</td>\n",
       "      <td>Jules Machias</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>★ The One Hundred Years of Lenni and Margot</td>\n",
       "      <td>Marianne Cronin</td>\n",
       "      <td>Fiction / Popular Fiction</td>\n",
       "      <td>Even in the face of death’s inevitability, fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We Can’t Keep Meeting Like This</td>\n",
       "      <td>Rachel Lynn Solomon</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>★ The Ride of Her Life</td>\n",
       "      <td>Elizabeth Letts</td>\n",
       "      <td>Nonfiction / Biography / Animals</td>\n",
       "      <td>This is a feel-good story in every way, and El...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>★ Golden Girl</td>\n",
       "      <td>Elin Hilderbrand</td>\n",
       "      <td>Fiction / Family Drama</td>\n",
       "      <td>Killing off the main character just a few page...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Road Trip</td>\n",
       "      <td>Beth O'Leary</td>\n",
       "      <td>Romance / Contemporary Romance</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Rescuer of Tiny Creatures</td>\n",
       "      <td>Curtis Manley, Lucy Ruth Cummins</td>\n",
       "      <td>Children's / Children's Picture Book</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Book Name  \\\n",
       "0                        ★ The Other Black Girl   \n",
       "1                    ★ Walking on Cowrie Shells   \n",
       "2                                 Malibu Rising   \n",
       "3                              Both Can Be True   \n",
       "4   ★ The One Hundred Years of Lenni and Margot   \n",
       "5               We Can’t Keep Meeting Like This   \n",
       "6                        ★ The Ride of Her Life   \n",
       "7                                 ★ Golden Girl   \n",
       "8                                 The Road Trip   \n",
       "9                 The Rescuer of Tiny Creatures   \n",
       "\n",
       "                        Author Name                                 Genre  \\\n",
       "0              Zakiya Dalila Harris            Fiction / Literary Fiction   \n",
       "1                       Nana Nkweti               Fiction / Short Stories   \n",
       "2               Taylor Jenkins Reid             Fiction / Popular Fiction   \n",
       "3                     Jules Machias             Children's / Middle Grade   \n",
       "4                   Marianne Cronin             Fiction / Popular Fiction   \n",
       "5               Rachel Lynn Solomon                       YA / YA Fiction   \n",
       "6                   Elizabeth Letts      Nonfiction / Biography / Animals   \n",
       "7                  Elin Hilderbrand                Fiction / Family Drama   \n",
       "8                      Beth O'Leary        Romance / Contemporary Romance   \n",
       "9  Curtis Manley, Lucy Ruth Cummins  Children's / Children's Picture Book   \n",
       "\n",
       "                                              Review  \n",
       "0  Brilliantly positioned at the intersection of ...  \n",
       "1  With the ease of a master, Nana Nkweti shifts ...  \n",
       "2  Malibu Rising is packed with plenty of scintil...  \n",
       "3                                                     \n",
       "4  Even in the face of death’s inevitability, fri...  \n",
       "5                                                     \n",
       "6  This is a feel-good story in every way, and El...  \n",
       "7  Killing off the main character just a few page...  \n",
       "8                                                     \n",
       "9                                                     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Book Name']=book_name\n",
    "df['Author Name']=author\n",
    "df['Genre']=genre\n",
    "df['Review']=review\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cricket Ranking Mens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top ODI men's team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Match</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand\\nNZ</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia\\nAUS</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India\\nIND</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England\\nENG</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Africa\\nSA</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pakistan\\nPAK</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh\\nBAN</td>\n",
       "      <td>27</td>\n",
       "      <td>2,438</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>West Indies\\nWI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka\\nSL</td>\n",
       "      <td>24</td>\n",
       "      <td>1,876</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan\\nAFG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Netherlands\\nNED</td>\n",
       "      <td>5</td>\n",
       "      <td>249</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Ireland\\nIRE</td>\n",
       "      <td>19</td>\n",
       "      <td>807</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Zimbabwe\\nZIM</td>\n",
       "      <td>15</td>\n",
       "      <td>588</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Scotland\\nSCO</td>\n",
       "      <td>7</td>\n",
       "      <td>258</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Oman\\nOMA</td>\n",
       "      <td>7</td>\n",
       "      <td>240</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Nepal\\nNEP</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>UAE\\nUAE</td>\n",
       "      <td>9</td>\n",
       "      <td>190</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Namibia\\nNAM</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>United States\\nUSA</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Papua New Guinea\\nPNG</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                   Team Match Points Rating\n",
       "0     1        New Zealand\\nNZ    17  2,054    121\n",
       "1     2         Australia\\nAUS    25  2,945    118\n",
       "2     3             India\\nIND    29  3,344    115\n",
       "3     4           England\\nENG    27  3,100    115\n",
       "4     5       South Africa\\nSA    20  2,137    107\n",
       "5     6          Pakistan\\nPAK    24  2,323     97\n",
       "6     7        Bangladesh\\nBAN    27  2,438     90\n",
       "7     8        West Indies\\nWI    27  2,222     82\n",
       "8     9          Sri Lanka\\nSL    24  1,876     78\n",
       "9    10       Afghanistan\\nAFG    17  1,054     62\n",
       "10   11       Netherlands\\nNED     5    249     50\n",
       "11   12           Ireland\\nIRE    19    807     42\n",
       "12   13          Zimbabwe\\nZIM    15    588     39\n",
       "13   14          Scotland\\nSCO     7    258     37\n",
       "14   15              Oman\\nOMA     7    240     34\n",
       "15   16             Nepal\\nNEP     5    119     24\n",
       "16   17               UAE\\nUAE     9    190     21\n",
       "17   18           Namibia\\nNAM     6     97     16\n",
       "18   19     United States\\nUSA     8     93     12\n",
       "19   20  Papua New Guinea\\nPNG     5      0      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url= \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "right_table=soup.find('table', class_='table')\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "E=[]\n",
    "#for making first heaader\n",
    "states = right_table.find('tr')\n",
    "s = states.find_all('th')\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "      # first row has no TH, but other rows have one TH and 6 TD\n",
    "    cells = row.findAll('td') \n",
    "    # first row has 7 TH \n",
    "    if len(cells) == 5:\n",
    "        A.append(cells[0].text.strip()) #rank,it is not position\n",
    "        #skip the sequence number column\n",
    "        B.append(cells[1].text.strip())\n",
    "        C.append(cells[2].text.strip())\n",
    "        D.append(cells[3].text.strip())\n",
    "        E.append(cells[4].text.strip())\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=A\n",
    "df['Team']=B\n",
    "df['Match']=C\n",
    "df['Points']=D\n",
    "df['Rating']=E\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 ODI Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank               Player Team Rating\n",
       "0    1           Babar Azam  PAK    865\n",
       "1    2          Virat Kohli  IND    857\n",
       "2    3         Rohit Sharma  IND    825\n",
       "3    4          Ross Taylor   NZ    801\n",
       "4    5          Aaron Finch  AUS    791\n",
       "5    6       Jonny Bairstow  ENG    785\n",
       "6    7         Fakhar Zaman  PAK    778\n",
       "7       Francois du Plessis   SA    778\n",
       "8    9         David Warner  AUS    773\n",
       "9                 Shai Hope   WI    773"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url= \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "right_table=soup.find('table', class_='table')\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "#for making first heaader\n",
    "states = right_table.find('tr')\n",
    "s = states.find_all('th')\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "      # first row has no TH, but other rows have one TH and 6 TD\n",
    "    cells = row.findAll('td') \n",
    "    # first row has 7 TH \n",
    "    if len(cells) == 5:\n",
    "        A.append(cells[0].text.strip()) #rank,it is not position\n",
    "        #skip the sequence number column\n",
    "        B.append(cells[1].text.strip())\n",
    "        C.append(cells[2].text.strip())\n",
    "        D.append(cells[3].text.strip())\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=A\n",
    "df['Player']=B\n",
    "df['Team']=C\n",
    "df['Rating']=D\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 ODI Bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9\\n        \\n\\n\\n\\nThis player has moved up in...</td>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10\\n        \\n\\n\\n\\nThis player has moved down...</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Rank             Player Team  \\\n",
       "0                                                  1        Trent Boult   NZ   \n",
       "1                                                  2       Mehedi Hasan  BAN   \n",
       "2                                                  3   Mujeeb Ur Rahman  AFG   \n",
       "3                                                  4         Matt Henry   NZ   \n",
       "4                                                  5     Jasprit Bumrah  IND   \n",
       "5                                                  6      Kagiso Rabada   SA   \n",
       "6                                                  7       Chris Woakes  ENG   \n",
       "7                                                  8     Josh Hazlewood  AUS   \n",
       "8  9\\n        \\n\\n\\n\\nThis player has moved up in...        Pat Cummins  AUS   \n",
       "9  10\\n        \\n\\n\\n\\nThis player has moved down...  Mustafizur Rahman  BAN   \n",
       "\n",
       "  Rating  \n",
       "0    737  \n",
       "1    713  \n",
       "2    708  \n",
       "3    691  \n",
       "4    690  \n",
       "5    666  \n",
       "6    665  \n",
       "7    660  \n",
       "8    646  \n",
       "9    645  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url= \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "right_table=soup.find('table', class_='table')\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "#for making first heaader\n",
    "states = right_table.find('tr')\n",
    "s = states.find_all('th')\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "      # first row has no TH, but other rows have one TH and 6 TD\n",
    "    cells = row.findAll('td') \n",
    "    # first row has 7 TH \n",
    "    if len(cells) == 5:\n",
    "        A.append(cells[0].text.strip()) #rank,it is not position\n",
    "        #skip the sequence number column\n",
    "        B.append(cells[1].text.strip())\n",
    "        C.append(cells[2].text.strip())\n",
    "        D.append(cells[3].text.strip())\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=A\n",
    "df['Player']=B\n",
    "df['Team']=C\n",
    "df['Rating']=D\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cricket Ranking Women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 ODI teams in women’s cricket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Match</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia\\nAUS</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa\\nSA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>England\\nENG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India\\nIND</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand\\nNZ</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies\\nWI</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Pakistan\\nPAK</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Bangladesh\\nBAN</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka\\nSL</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ireland\\nIRE</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank              Team Match Points Rating\n",
       "0    1    Australia\\nAUS    18  2,955    164\n",
       "1    2  South Africa\\nSA    24  2,828    118\n",
       "2    3      England\\nENG    17  1,993    117\n",
       "3    4        India\\nIND    20  2,226    111\n",
       "4    5   New Zealand\\nNZ    21  1,947     93\n",
       "5    6   West Indies\\nWI    12  1,025     85\n",
       "6    7     Pakistan\\nPAK    15  1,101     73\n",
       "7    8   Bangladesh\\nBAN     5    306     61\n",
       "8    9     Sri Lanka\\nSL    11    519     47\n",
       "9   10      Ireland\\nIRE     2     25     13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url= \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "right_table=soup.find('table', class_='table')\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "E=[]\n",
    "#for making first heaader\n",
    "states = right_table.find('tr')\n",
    "s = states.find_all('th')\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "      # first row has no TH, but other rows have one TH and 6 TD\n",
    "    cells = row.findAll('td') \n",
    "    # first row has 7 TH \n",
    "    if len(cells) == 5:\n",
    "        A.append(cells[0].text.strip()) #rank,it is not position\n",
    "        #skip the sequence number column\n",
    "        B.append(cells[1].text.strip())\n",
    "        C.append(cells[2].text.strip())\n",
    "        D.append(cells[3].text.strip())\n",
    "        E.append(cells[4].text.strip())\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=A\n",
    "df['Team']=B\n",
    "df['Match']=C\n",
    "df['Points']=D\n",
    "df['Rating']=E\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 women’s ODI players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9\\n        \\n\\n\\n\\nThis player has moved up in...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10\\n        \\n\\n\\n\\nThis player has moved up i...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Rank             Player Team  \\\n",
       "0                                                  1     Tammy Beaumont  ENG   \n",
       "1                                                  2        Lizelle Lee   SA   \n",
       "2                                                  3       Alyssa Healy  AUS   \n",
       "3                                                  4    Stafanie Taylor   WI   \n",
       "4                                                  5        Meg Lanning  AUS   \n",
       "5                                                  6  Amy Satterthwaite   NZ   \n",
       "6                                                  7    Smriti Mandhana  IND   \n",
       "7                                                  8        Mithali Raj  IND   \n",
       "8  9\\n        \\n\\n\\n\\nThis player has moved up in...     Natalie Sciver  ENG   \n",
       "9  10\\n        \\n\\n\\n\\nThis player has moved up i...    Laura Wolvaardt   SA   \n",
       "\n",
       "  Points  \n",
       "0    765  \n",
       "1    758  \n",
       "2    756  \n",
       "3    746  \n",
       "4    723  \n",
       "5    715  \n",
       "6    710  \n",
       "7    709  \n",
       "8    685  \n",
       "9    683  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url= \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "right_table=soup.find('table', class_='table')\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "#for making first heaader\n",
    "states = right_table.find('tr')\n",
    "s = states.find_all('th')\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "      # first row has no TH, but other rows have one TH and 6 TD\n",
    "    cells = row.findAll('td') \n",
    "    # first row has 7 TH \n",
    "    if len(cells) == 5:\n",
    "        A.append(cells[0].text.strip()) #rank,it is not position\n",
    "        #skip the sequence number column\n",
    "        B.append(cells[1].text.strip())\n",
    "        C.append(cells[2].text.strip())\n",
    "        D.append(cells[3].text.strip())\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=A\n",
    "df['Player']=B\n",
    "df['Team']=C\n",
    "df['Points']=D\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 women’s ODI all-rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This player has moved down in the rankings sin...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8\\n        \\n\\n\\n\\nThis player has moved up in...</td>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9\\n        \\n\\n\\n\\nThis player has moved down ...</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10\\n        \\n\\n\\n\\nThis player has moved down...</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Rank            Player Team  \\\n",
       "0                                                  1    Marizanne Kapp   SA   \n",
       "1  This player has moved down in the rankings sin...      Ellyse Perry  AUS   \n",
       "2                                                  3   Stafanie Taylor   WI   \n",
       "3                                                  4    Natalie Sciver  ENG   \n",
       "4                                                  5     Deepti Sharma  IND   \n",
       "5                                                  6     Jess Jonassen  AUS   \n",
       "6                                                  7  Ashleigh Gardner  AUS   \n",
       "7  8\\n        \\n\\n\\n\\nThis player has moved up in...  Dane van Niekerk   SA   \n",
       "8  9\\n        \\n\\n\\n\\nThis player has moved down ...     Sophie Devine   NZ   \n",
       "9  10\\n        \\n\\n\\n\\nThis player has moved down...       Amelia Kerr   NZ   \n",
       "\n",
       "  Points  \n",
       "0    418  \n",
       "1    418  \n",
       "2    410  \n",
       "3    349  \n",
       "4    343  \n",
       "5    307  \n",
       "6    252  \n",
       "7    243  \n",
       "8    242  \n",
       "9    236  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url= \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "right_table=soup.find('table', class_='table')\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "D=[]\n",
    "E=[]\n",
    "#for making first heaader\n",
    "states = right_table.find('tr')\n",
    "s = states.find_all('th')\n",
    "\n",
    "for row in right_table.findAll('tr'):\n",
    "      # first row has no TH, but other rows have one TH and 6 TD\n",
    "    cells = row.findAll('td') \n",
    "    # first row has 7 TH \n",
    "    if len(cells) == 5:\n",
    "        A.append(cells[0].text.strip()) #rank,it is not position\n",
    "        #skip the sequence number column\n",
    "        B.append(cells[1].text.strip())\n",
    "        C.append(cells[2].text.strip())\n",
    "        D.append(cells[3].text.strip())\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=A\n",
    "df['Player']=B\n",
    "df['Team']=C\n",
    "df['Points']=D\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mobile phones under Rs. 20,000 listed on Amazon.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8,799',\n",
       " '10,999',\n",
       " '14,999',\n",
       " '11,990',\n",
       " '8,999',\n",
       " '12,999',\n",
       " '11,990',\n",
       " '14,490',\n",
       " '10,999',\n",
       " '7,499',\n",
       " '8,799',\n",
       " '6,999',\n",
       " '7,499',\n",
       " '5,000',\n",
       " '7,499',\n",
       " '8,999']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#price\n",
    "page = requests.get('https://www.amazon.in/s?k=mobile&rh=p_36%3A-2000000&qid=1622736496&rnid=1318502031&ref=sr_nr_p_36_5')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all(\"span\",class_=\"a-price-whole\")\n",
    "a=[]\n",
    "for i in name:\n",
    "    a.append(i.text.replace(\"\\n\",\"\"))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40,774',\n",
       " '15,836',\n",
       " '187,645',\n",
       " '13,147',\n",
       " '1,466',\n",
       " '30,447',\n",
       " '13,147',\n",
       " '24',\n",
       " '61,489',\n",
       " 'Save ₹500',\n",
       " '45,209',\n",
       " '40,774',\n",
       " '45,209',\n",
       " '45,209',\n",
       " '3,340',\n",
       " '45,209',\n",
       " '770',\n",
       " 'mobile realme mobile',\n",
       " 'samsung',\n",
       " 'mobile vivo',\n",
       " 'mobile oppo',\n",
       " 'redmi',\n",
       " 'mobile under 5000',\n",
       " ' or ',\n",
       " 'Department',\n",
       " 'Smartphones & Basic Mobiles',\n",
       " 'Smartphones',\n",
       " 'Basic Mobiles',\n",
       " 'Electronics',\n",
       " 'Avg. Customer Review',\n",
       " 'Brand',\n",
       " 'Redmi',\n",
       " 'Samsung',\n",
       " 'Oppo',\n",
       " 'OnePlus',\n",
       " 'Vivo',\n",
       " 'Panasonic',\n",
       " 'realme',\n",
       " 'Apple',\n",
       " 'Tecno',\n",
       " 'MI',\n",
       " 'IKALL',\n",
       " 'Nokia',\n",
       " 'LG',\n",
       " 'Micromax',\n",
       " 'Motorola',\n",
       " 'Lava',\n",
       " 'Snexian',\n",
       " 'itel',\n",
       " 'Generic',\n",
       " 'Gionee',\n",
       " 'Xifo',\n",
       " 'Coolpad',\n",
       " 'Xiaomi',\n",
       " 'BlackBerry',\n",
       " 'Nillkin',\n",
       " 'FORME',\n",
       " 'Huawei',\n",
       " 'ASUS',\n",
       " 'Lenovo',\n",
       " 'Energizer',\n",
       " 'Zopo',\n",
       " 'Intex',\n",
       " 'Portronics',\n",
       " 'Elv',\n",
       " 'Leoie',\n",
       " 'Tygot',\n",
       " 'Moto',\n",
       " 'R',\n",
       " 'Google',\n",
       " 'Vaku Luxos',\n",
       " 'Price',\n",
       " 'Any Price',\n",
       " 'Under ₹1,000',\n",
       " '₹1,000 - ₹5,000',\n",
       " '₹5,000 - ₹10,000',\n",
       " '₹10,000 - ₹20,000',\n",
       " 'Deals',\n",
       " \"Today's Deals\",\n",
       " 'Mobile Phone Operating System',\n",
       " 'Android',\n",
       " 'Bada',\n",
       " 'Blackberry',\n",
       " 'iOS',\n",
       " 'Palm Web OS',\n",
       " 'Symbian',\n",
       " 'WebOS',\n",
       " 'Windows Phone',\n",
       " 'Pay On Delivery',\n",
       " 'Eligible for Pay On Delivery',\n",
       " 'Internal Memory',\n",
       " 'Less than 3.9 GB',\n",
       " '4 GB',\n",
       " '8 GB',\n",
       " '16 GB',\n",
       " '32 GB',\n",
       " '64 GB',\n",
       " '128 GB',\n",
       " '256 GB & above',\n",
       " 'RAM',\n",
       " '8GB & above',\n",
       " '6GB',\n",
       " '4GB',\n",
       " '3 GB',\n",
       " '2 GB',\n",
       " '1 GB',\n",
       " 'Less Than 512 MB',\n",
       " 'Number of Cores',\n",
       " 'Single Core',\n",
       " 'Dual Core',\n",
       " 'Triple Core',\n",
       " 'Quad Core',\n",
       " 'Hexa Core',\n",
       " 'Octa Core',\n",
       " 'Screen Size',\n",
       " 'Below 3.9 Inches',\n",
       " '4 To 4.4 Inches',\n",
       " '4.5 To 4.9 Inches',\n",
       " '5 To 5.4 Inches',\n",
       " '5.5 Inches & Above',\n",
       " 'Processor Speed',\n",
       " 'Less Than 0.99 GHz',\n",
       " '1 - 1.49 GHz',\n",
       " '1.5 - 1.99 GHz',\n",
       " '2 - 2.4 GHz',\n",
       " '2.5 GHz & Above',\n",
       " 'Battery Capacity',\n",
       " 'Less Than 999 mAh',\n",
       " '1000 - 1999 mAh',\n",
       " '2000 - 2999 mAh',\n",
       " '3000 - 3999 mAh',\n",
       " '4000 mAh & More',\n",
       " 'Colour',\n",
       " 'Front Camera Resolution',\n",
       " 'Up to 3.9 MP',\n",
       " '4 - 7.9 MP',\n",
       " '8 - 11.9 MP',\n",
       " '12 - 15.9 MP',\n",
       " '16 - 19.9 MP',\n",
       " '20 - 23.9 MP',\n",
       " '24 - 27.9 MP',\n",
       " '28 - 31.9 MP',\n",
       " '32 MP & Above',\n",
       " 'Mobile Phone Primary Camera Resolution',\n",
       " 'Up to 3.9 MP',\n",
       " '4 - 7.9 MP',\n",
       " '8 - 11.9 MP',\n",
       " '12 - 15.9 MP',\n",
       " '16 - 19.9 MP',\n",
       " '20 - 23.9 MP',\n",
       " '24 - 27.9 MP',\n",
       " '28 - 31.9 MP',\n",
       " '32 MP & Above',\n",
       " 'Device Features',\n",
       " 'Bluetooth Tethering',\n",
       " 'Dual SIM',\n",
       " 'E-Mail',\n",
       " 'GPS',\n",
       " 'Hotspot',\n",
       " 'Internet',\n",
       " 'MP3',\n",
       " 'Music Player',\n",
       " 'Primary Camera',\n",
       " 'Radio',\n",
       " 'Secondary Camera',\n",
       " 'Touchscreen',\n",
       " 'USB',\n",
       " 'WAP',\n",
       " 'Data Transfer',\n",
       " '3G',\n",
       " '4G',\n",
       " 'Edge',\n",
       " 'GPRS',\n",
       " 'GSM',\n",
       " 'WiFi',\n",
       " 'Item Condition',\n",
       " 'New',\n",
       " 'Discount',\n",
       " '10% Off or more',\n",
       " '25% Off or more',\n",
       " '35% Off or more',\n",
       " '50% Off or more',\n",
       " 'Availability',\n",
       " 'Include Out of Stock']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average rating\n",
    "name=soup.find_all(\"span\",class_=\"a-size-base\")\n",
    "b=[]\n",
    "for i in name:\n",
    "    b.append(i.text.replace(\"\\n\",\"\"))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Image\n",
    "name=soup.find_all(\"div\",class_=\"a-section aok-relative s-image-fixed-height\")\n",
    "c=[]\n",
    "for i in name:\n",
    "    c.append(i.text.replace(\"\\n\",\"\"))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 5000 mAh| 2.3GHz Mediatek Helio G35 Octa core Processor',\n",
       " 'Samsung Galaxy M12 (Blue,4GB RAM, 64GB Storage) 6000 mAh with 8nm Processor | True 48 MP Quad Camera | 90Hz Refresh Rate',\n",
       " 'Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB Storage)',\n",
       " 'Oppo A31 (Mystery Black, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Storage) - 6000mAh Battery |FHD+ Screen| 48MP Quad Camera | Snapdragon 662 Processor',\n",
       " 'Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Oppo A54 (Crystal Black, 4GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers',\n",
       " 'Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storage) - 48MP Quad Camera & Full HD+ Display',\n",
       " 'Redmi 9A (Nature Green, 3GB Ram, 32GB Storage) | 2GHz Octa-core Helio G25 Processor',\n",
       " 'Redmi 9 (Carbon Black, 4GB RAM, 64GB Storage) | 5000 mAh| 2.3GHz Mediatek Helio G35 Octa core Processor',\n",
       " 'Redmi 9A (Midnight Black 2GB RAM 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery',\n",
       " 'Redmi 9A (Sea Blue 3GB RAM 32GB Storage)| 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery',\n",
       " 'Panasonic Eluga i7 (2GB RAM, 16GB Storage, Finger Print Sensor, 4000mAh Battery) (Black)',\n",
       " 'Redmi 9A(Midnight Black 3GB RAM 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery',\n",
       " 'Samsung Galaxy M11 (Violet, 4GB RAM, 64GB Storage) with No Cost EMI/Additional Exchange Offers']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Product Name\n",
    "pname=soup.find_all(\"span\",class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "c=[]\n",
    "for i in pname:\n",
    "    c.append(i.text.replace(\"\\n\",\"\"))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local weather from the National Weather Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today',\n",
       " 'Tonight',\n",
       " 'Friday',\n",
       " 'FridayNight',\n",
       " 'Saturday',\n",
       " 'SaturdayNight',\n",
       " 'Sunday',\n",
       " 'SundayNight',\n",
       " 'Monday']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://forecast.weather.gov/MapClick.php?lat=37.77493000000004&lon=-122.41941999999995#.YLjrj6gza00')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all(\"p\",class_=\"period-name\")\n",
    "day=[]\n",
    "for i in name:\n",
    "    day.append(i.text.replace(\"\\n\",\"\"))\n",
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunny thenSunny andBreezy',\n",
       " 'IncreasingClouds',\n",
       " 'Mostly Sunnythen Sunnyand Breezy',\n",
       " 'Mostly Clearand Breezythen MostlyClear',\n",
       " 'Sunny',\n",
       " 'Mostly Clear',\n",
       " 'Sunny',\n",
       " 'Mostly Clear',\n",
       " 'Sunny']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days=soup.find_all(\"p\",class_=\"short-desc\")\n",
    "desc=[]\n",
    "for i in days:\n",
    "    desc.append(i.text.replace(\"\\n\",\"\"))\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High: 68 °F', 'High: 68 °F', 'High: 68 °F', 'High: 67 °F', 'High: 64 °F']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=soup.find_all(\"p\",class_=\"temp temp-high\")\n",
    "temp=[]\n",
    "for i in t:\n",
    "    temp.append(i.text.replace(\"\\n\",\"\"))\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fresher job listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customer Service Specialist ',\n",
       " 'Graphic Designer ',\n",
       " 'Digital Marketing Specialist ',\n",
       " 'Junior Corporate Sales Executive ',\n",
       " 'Backend Developer ',\n",
       " 'Junior Operations Executive ',\n",
       " 'Internal Audit Associate ',\n",
       " 'Business Marketing Manager ',\n",
       " 'React Native Developer ',\n",
       " 'Research And Communications Associate ',\n",
       " 'Data Scientist ',\n",
       " 'Data Science Django Developer ',\n",
       " 'Corporate Sales Associate ',\n",
       " 'Full Stack Developer ',\n",
       " 'Full Stack Developer (MERN) ',\n",
       " 'Business Development Executive ',\n",
       " 'Sales Development Representative ',\n",
       " 'Graphic Designer ',\n",
       " 'Operations Executive ',\n",
       " 'Business Development Executive ',\n",
       " 'Admission Counselor (Sales) ',\n",
       " 'Sales And Business Development Analyst ',\n",
       " 'Growth Hacking Digital Marketer ',\n",
       " 'Junior Node.js Developer ',\n",
       " 'Junior Digital Marketing Executive ',\n",
       " 'iOS App Developer ',\n",
       " 'Food Journalist ',\n",
       " 'Junior Software Developer ',\n",
       " 'Full Stack Developer ',\n",
       " 'Business Analyst ',\n",
       " 'Associate Full Stack Developer ',\n",
       " 'Full Stack Engineer ',\n",
       " 'Product Marketer ',\n",
       " 'Business Development Executive ',\n",
       " 'Associate - Business Development ',\n",
       " 'Research Analyst (Economics) ',\n",
       " 'Machine Learning Engineer ',\n",
       " 'Business Analyst ',\n",
       " 'Business Development Executive (Inside Sales) ',\n",
       " 'Business Development Associate ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://internshala.com/fresher-jobs/matching-preferences/page-1')\n",
    "soup=BeautifulSoup(page.content)\n",
    "job=soup.find_all(\"div\",class_=\"heading_4_5 profile\")\n",
    "title=[]\n",
    "for i in job:\n",
    "    title.append(i.text.replace(\"\\n\",\"\"))\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wono Inc',\n",
       " 'Wono Inc',\n",
       " 'Wono Inc',\n",
       " 'Wyntem',\n",
       " 'HomeJam',\n",
       " 'NCTI LLP',\n",
       " 'Transpeninsula LLC',\n",
       " 'MentorBoxx',\n",
       " 'Runners Planet',\n",
       " 'Institute For Governance, Policies & Politics',\n",
       " 'ProtonAutoML',\n",
       " 'Markytics',\n",
       " 'MiM-Essay',\n",
       " 'Wondermail',\n",
       " 'Project Tinker',\n",
       " 'Kaizen Academy',\n",
       " 'Amigobulls',\n",
       " 'Underground Movement LLP',\n",
       " 'Alphacore Technologies Private Limited',\n",
       " 'Ruhcom Enterprises Private Limited',\n",
       " 'Sky Education Group',\n",
       " \"Mo's F&B Group\",\n",
       " 'Sleep Love',\n",
       " 'Askadmissions.ai',\n",
       " 'Krivy',\n",
       " 'Ascentspark Software Private Limited',\n",
       " 'Truffle Nation',\n",
       " 'Habitate Technologies Private Limited',\n",
       " 'SoluLab',\n",
       " 'SoluLab',\n",
       " 'REPOZITORY TECHNOLOGIES PRIVATE LIMITED',\n",
       " 'Beehive Academy India',\n",
       " 'Bip',\n",
       " 'Tabeazy',\n",
       " 'Leverage Edu',\n",
       " 'DEX-DEFT Research And Consulting OPC Private Limited',\n",
       " 'AIMonk Labs Technology Limited',\n",
       " 'Kasper Consulting Private Limited',\n",
       " 'GREedge',\n",
       " 'PEPKIDZ LEARNING']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cname=soup.find_all(\"div\",class_=\"heading_6 company_name\")\n",
    "company_name=[]\n",
    "for i in cname:\n",
    "    company_name.append(i.text.strip())\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Starts\\xa0Immediately',\n",
       " '5.2 - 6.4 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '7 - 8.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.8 - 6 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 - 8.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '6.62 - 7.95 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"2 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"2 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.5 LPA',\n",
       " \"2 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 - 7 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4 - 7.2 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.5 - 6 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.5 - 6.5 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"1 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.1 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.5 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.6 - 7 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.5 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5.2 - 7 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 5 LPA',\n",
       " \"28 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4.2 LPA',\n",
       " \"28 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 3.6 LPA',\n",
       " \"30 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '4.2 - 8.2 LPA',\n",
       " \"28 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 6 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.6 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 LPA',\n",
       " \"3 Jul' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '5 - 6.5 LPA',\n",
       " \"27 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.25 - 4 LPA',\n",
       " \"26 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3.75 LPA',\n",
       " \"26 Jun' 21\",\n",
       " 'Starts\\xa0Immediately',\n",
       " '3 - 4 LPA',\n",
       " \"25 Jun' 21\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pay=soup.find_all(\"div\",class_=\"item_body\")\n",
    "ctc=[]\n",
    "for i in pay:\n",
    "    ctc.append(i.text.strip())\n",
    "ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
